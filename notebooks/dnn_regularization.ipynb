{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularizing a deep neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory:  /Users/irellzane/MLprojects/CIFAR-100-DNN-Optimization\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if os.getcwd().endswith(\"notebooks\"):\n",
    "    os.chdir('..')\n",
    "\n",
    "print(\"Current working directory: \", os.getcwd())\n",
    "if not os.getcwd().endswith(\"CIFAR-100-DNN-Optimization\"):\n",
    "    raise ValueError(\"Please change working directory to 'path/CIFAR-100-DNN-Optimization' before proceeding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: setuptools>=42 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 1)) (70.1.1)\n",
      "Requirement already satisfied: numpy>=1.26.4 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 2)) (1.26.4)\n",
      "Requirement already satisfied: pandas>=2.2.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 3)) (2.2.2)\n",
      "Requirement already satisfied: scikit-learn>=1.4.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 4)) (1.5.0)\n",
      "Requirement already satisfied: matplotlib>=3.8.3 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 5)) (3.9.0)\n",
      "Requirement already satisfied: tensorflow==2.16.1 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 6)) (2.16.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in ./.venv/lib/python3.12/site-packages (from tensorflow==2.16.1->-r requirements.txt (line 6)) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in ./.venv/lib/python3.12/site-packages (from tensorflow==2.16.1->-r requirements.txt (line 6)) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in ./.venv/lib/python3.12/site-packages (from tensorflow==2.16.1->-r requirements.txt (line 6)) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in ./.venv/lib/python3.12/site-packages (from tensorflow==2.16.1->-r requirements.txt (line 6)) (0.5.5)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in ./.venv/lib/python3.12/site-packages (from tensorflow==2.16.1->-r requirements.txt (line 6)) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in ./.venv/lib/python3.12/site-packages (from tensorflow==2.16.1->-r requirements.txt (line 6)) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in ./.venv/lib/python3.12/site-packages (from tensorflow==2.16.1->-r requirements.txt (line 6)) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in ./.venv/lib/python3.12/site-packages (from tensorflow==2.16.1->-r requirements.txt (line 6)) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in ./.venv/lib/python3.12/site-packages (from tensorflow==2.16.1->-r requirements.txt (line 6)) (3.3.0)\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.12/site-packages (from tensorflow==2.16.1->-r requirements.txt (line 6)) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in ./.venv/lib/python3.12/site-packages (from tensorflow==2.16.1->-r requirements.txt (line 6)) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./.venv/lib/python3.12/site-packages (from tensorflow==2.16.1->-r requirements.txt (line 6)) (2.32.3)\n",
      "Requirement already satisfied: six>=1.12.0 in ./.venv/lib/python3.12/site-packages (from tensorflow==2.16.1->-r requirements.txt (line 6)) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./.venv/lib/python3.12/site-packages (from tensorflow==2.16.1->-r requirements.txt (line 6)) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in ./.venv/lib/python3.12/site-packages (from tensorflow==2.16.1->-r requirements.txt (line 6)) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in ./.venv/lib/python3.12/site-packages (from tensorflow==2.16.1->-r requirements.txt (line 6)) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./.venv/lib/python3.12/site-packages (from tensorflow==2.16.1->-r requirements.txt (line 6)) (1.64.1)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in ./.venv/lib/python3.12/site-packages (from tensorflow==2.16.1->-r requirements.txt (line 6)) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in ./.venv/lib/python3.12/site-packages (from tensorflow==2.16.1->-r requirements.txt (line 6)) (3.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.12/site-packages (from pandas>=2.2.0->-r requirements.txt (line 3)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.12/site-packages (from pandas>=2.2.0->-r requirements.txt (line 3)) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.12/site-packages (from pandas>=2.2.0->-r requirements.txt (line 3)) (2024.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn>=1.4.0->-r requirements.txt (line 4)) (1.14.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn>=1.4.0->-r requirements.txt (line 4)) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn>=1.4.0->-r requirements.txt (line 4)) (3.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.12/site-packages (from matplotlib>=3.8.3->-r requirements.txt (line 5)) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.12/site-packages (from matplotlib>=3.8.3->-r requirements.txt (line 5)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.12/site-packages (from matplotlib>=3.8.3->-r requirements.txt (line 5)) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.12/site-packages (from matplotlib>=3.8.3->-r requirements.txt (line 5)) (1.4.5)\n",
      "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.12/site-packages (from matplotlib>=3.8.3->-r requirements.txt (line 5)) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.12/site-packages (from matplotlib>=3.8.3->-r requirements.txt (line 5)) (3.1.2)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./.venv/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow==2.16.1->-r requirements.txt (line 6)) (0.43.0)\n",
      "Requirement already satisfied: rich in ./.venv/lib/python3.12/site-packages (from keras>=3.0.0->tensorflow==2.16.1->-r requirements.txt (line 6)) (13.7.1)\n",
      "Requirement already satisfied: namex in ./.venv/lib/python3.12/site-packages (from keras>=3.0.0->tensorflow==2.16.1->-r requirements.txt (line 6)) (0.0.8)\n",
      "Requirement already satisfied: optree in ./.venv/lib/python3.12/site-packages (from keras>=3.0.0->tensorflow==2.16.1->-r requirements.txt (line 6)) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.16.1->-r requirements.txt (line 6)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.16.1->-r requirements.txt (line 6)) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.16.1->-r requirements.txt (line 6)) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.16.1->-r requirements.txt (line 6)) (2024.6.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./.venv/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.1->-r requirements.txt (line 6)) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./.venv/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.1->-r requirements.txt (line 6)) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in ./.venv/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.1->-r requirements.txt (line 6)) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in ./.venv/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow==2.16.1->-r requirements.txt (line 6)) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./.venv/lib/python3.12/site-packages (from rich->keras>=3.0.0->tensorflow==2.16.1->-r requirements.txt (line 6)) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.venv/lib/python3.12/site-packages (from rich->keras>=3.0.0->tensorflow==2.16.1->-r requirements.txt (line 6)) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./.venv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow==2.16.1->-r requirements.txt (line 6)) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Flatten, Input, BatchNormalization, Activation\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneCycleScheduler(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, iterations, max_rate, start_rate=None,\n",
    "                 last_iterations=None, last_rate=None):\n",
    "        self.iterations = iterations\n",
    "        self.max_rate = max_rate\n",
    "        self.start_rate = start_rate or max_rate / 10\n",
    "        self.last_iterations = last_iterations or iterations // 10 + 1\n",
    "        self.half_iteration = (iterations - self.last_iterations) // 2\n",
    "        self.last_rate = last_rate or self.start_rate / 1000\n",
    "        self.iteration = 0\n",
    "    def _interpolate(self, iter1, iter2, rate1, rate2):\n",
    "        return ((rate2 - rate1) * (self.iteration - iter1)\n",
    "                / (iter2 - iter1) + rate1)\n",
    "    def on_batch_begin(self, batch, logs):\n",
    "        if self.iteration < self.half_iteration:\n",
    "            rate = self._interpolate(0, self.half_iteration, self.start_rate, self.max_rate)\n",
    "        elif self.iteration < 2 * self.half_iteration:\n",
    "            rate = self._interpolate(self.half_iteration, 2 * self.half_iteration,\n",
    "                                     self.max_rate, self.start_rate)\n",
    "        else:\n",
    "            rate = self._interpolate(2 * self.half_iteration, self.iterations,\n",
    "                                     self.start_rate, self.last_rate)\n",
    "        self.iteration += 1\n",
    "        self.model.optimizer.learning_rate = rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "data_pre_path = './data/CIFAR-100/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_path = data_pre_path + 'train'\n",
    "data_test_path = data_pre_path + 'test'\n",
    "data_train_dict = unpickle(data_train_path)\n",
    "data_test_dict = unpickle(data_test_path)\n",
    "data_train = data_train_dict[b'data']\n",
    "y_train_valid = np.array(data_train_dict[b'fine_labels'])\n",
    "data_test = data_test_dict[b'data']\n",
    "y_test = np.array(data_test_dict[b'fine_labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_valid = data_train.reshape(-1, 3, 32, 32).transpose(0,2,3,1) / 255\n",
    "X_test = data_test.reshape(-1, 3, 32, 32).transpose(0,2,3,1) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = X_train_valid[0].shape\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_valid, y_train_valid, test_size=5000/50000, stratify=y_train_valid, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L2 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Input(shape=input_shape))\n",
    "model.add(Flatten())\n",
    "\n",
    "for _ in range(10):\n",
    "    model.add(Dense(400, activation=\"swish\", kernel_initializer=\"he_normal\", kernel_regularizer=l2(0.01)))\n",
    "    \n",
    "model.add(Dense(100, activation=\"softmax\"))\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(nesterov=True, learning_rate=0.05)\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 30\n",
    "batch_size = 128\n",
    "onecycle = OneCycleScheduler(np.ceil(len(X_train) / batch_size) * n_epochs,\n",
    "                             max_rate=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 31ms/step - accuracy: 0.0130 - loss: 71.0393 - val_accuracy: 0.0200 - val_loss: 35.8420\n",
      "Epoch 2/30\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - accuracy: 0.0217 - loss: 28.2146 - val_accuracy: 0.0196 - val_loss: 12.2408\n",
      "Epoch 3/30\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 31ms/step - accuracy: 0.0190 - loss: 9.9001 - val_accuracy: 0.0194 - val_loss: 5.7887\n",
      "Epoch 4/30\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 33ms/step - accuracy: 0.0137 - loss: 5.3799 - val_accuracy: 0.0100 - val_loss: 4.7293\n",
      "Epoch 5/30\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 42ms/step - accuracy: 0.0090 - loss: 4.6799 - val_accuracy: 0.0100 - val_loss: 4.6127\n",
      "Epoch 6/30\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 38ms/step - accuracy: 0.0092 - loss: 4.6105 - val_accuracy: 0.0100 - val_loss: 4.6056\n",
      "Epoch 7/30\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 36ms/step - accuracy: 0.0087 - loss: 4.6066 - val_accuracy: 0.0100 - val_loss: 4.6053\n",
      "Epoch 8/30\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 31ms/step - accuracy: 0.0091 - loss: 4.6066 - val_accuracy: 0.0100 - val_loss: 4.6054\n",
      "Epoch 9/30\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 29ms/step - accuracy: 0.0093 - loss: 4.6067 - val_accuracy: 0.0100 - val_loss: 4.6054\n",
      "Epoch 10/30\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - accuracy: 0.0092 - loss: 4.6069 - val_accuracy: 0.0100 - val_loss: 4.6054\n",
      "Epoch 11/30\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - accuracy: 0.0094 - loss: 4.6070 - val_accuracy: 0.0100 - val_loss: 4.6055\n",
      "Epoch 12/30\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 35ms/step - accuracy: 0.0094 - loss: 4.6072 - val_accuracy: 0.0100 - val_loss: 4.6055\n",
      "Epoch 13/30\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 41ms/step - accuracy: 0.0093 - loss: 4.6073 - val_accuracy: 0.0100 - val_loss: 4.6056\n",
      "Epoch 14/30\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 34ms/step - accuracy: 0.0093 - loss: 4.6074 - val_accuracy: 0.0100 - val_loss: 4.6056\n",
      "Epoch 15/30\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 40ms/step - accuracy: 0.0093 - loss: 4.6074 - val_accuracy: 0.0100 - val_loss: 4.6056\n",
      "Epoch 16/30\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 28ms/step - accuracy: 0.0094 - loss: 4.6073 - val_accuracy: 0.0100 - val_loss: 4.6055\n",
      "Epoch 17/30\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - accuracy: 0.0092 - loss: 4.6071 - val_accuracy: 0.0100 - val_loss: 4.6055\n",
      "Epoch 18/30\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 39ms/step - accuracy: 0.0093 - loss: 4.6070 - val_accuracy: 0.0100 - val_loss: 4.6054\n",
      "Epoch 19/30\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 43ms/step - accuracy: 0.0090 - loss: 4.6068 - val_accuracy: 0.0100 - val_loss: 4.6054\n",
      "Epoch 20/30\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 36ms/step - accuracy: 0.0087 - loss: 4.6067 - val_accuracy: 0.0100 - val_loss: 4.6053\n",
      "Epoch 21/30\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 28ms/step - accuracy: 0.0085 - loss: 4.6066 - val_accuracy: 0.0100 - val_loss: 4.6053\n",
      "Epoch 22/30\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 57ms/step - accuracy: 0.0083 - loss: 4.6064 - val_accuracy: 0.0100 - val_loss: 4.6053\n",
      "Epoch 23/30\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 46ms/step - accuracy: 0.0081 - loss: 4.6063 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
      "Epoch 24/30\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 39ms/step - accuracy: 0.0081 - loss: 4.6061 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
      "Epoch 25/30\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - accuracy: 0.0081 - loss: 4.6059 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
      "Epoch 26/30\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 35ms/step - accuracy: 0.0081 - loss: 4.6058 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
      "Epoch 27/30\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 33ms/step - accuracy: 0.0076 - loss: 4.6056 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
      "Epoch 28/30\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 33ms/step - accuracy: 0.0080 - loss: 4.6054 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
      "Epoch 29/30\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - accuracy: 0.0080 - loss: 4.6054 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
      "Epoch 30/30\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - accuracy: 0.0076 - loss: 4.6053 - val_accuracy: 0.0100 - val_loss: 4.6052\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    epochs=n_epochs,\n",
    "    batch_size=batch_size, \n",
    "    callbacks=[onecycle]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mplot_history\u001b[49m(history)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plot_history' is not defined"
     ]
    }
   ],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2046 - loss: 6.4317\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[6.342916488647461, 0.21040000021457672]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.2079 - loss: 6.4189\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[6.3947062492370605, 0.20890000462532043]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
